{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\n#from sklearn.\n\ndata=pd.read_csv('../input/heartdisease-2/heart_disease.csv')\nlabels=data.values[:,-1]\nlabels[labels>1]=1\nlabels=labels.astype(int)\n\ndata=data.values[:,:-1]","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-04-29T11:58:45.273202Z","iopub.execute_input":"2022-04-29T11:58:45.274905Z","iopub.status.idle":"2022-04-29T11:58:45.307687Z","shell.execute_reply.started":"2022-04-29T11:58:45.274732Z","shell.execute_reply":"2022-04-29T11:58:45.306429Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:58:46.938546Z","iopub.execute_input":"2022-04-29T11:58:46.938918Z","iopub.status.idle":"2022-04-29T11:58:46.944624Z","shell.execute_reply.started":"2022-04-29T11:58:46.938882Z","shell.execute_reply":"2022-04-29T11:58:46.943875Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"num_estimator = 5\ncv = KFold(n_splits=5)\nbase_learners = [\n                 ('dt_1', DecisionTreeClassifier(random_state=0, criterion='gini', splitter='random')),\n                 ('dt_2', DecisionTreeClassifier(random_state=0, criterion='gini', splitter='best')),\n                 ('dt_3', DecisionTreeClassifier(random_state=0, criterion='entropy', splitter='random')),\n                 ('dt_4', DecisionTreeClassifier(random_state=0, criterion='entropy', splitter='best')),\n                 ('dt_5', DecisionTreeClassifier(random_state=42, criterion='entropy', splitter='best'))\n                ]\nfinal_estimator = DecisionTreeClassifier(random_state=0, criterion='entropy', splitter='best')","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:58:50.007304Z","iopub.execute_input":"2022-04-29T11:58:50.007955Z","iopub.status.idle":"2022-04-29T11:58:50.016360Z","shell.execute_reply.started":"2022-04-29T11:58:50.007902Z","shell.execute_reply":"2022-04-29T11:58:50.015563Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"%%time\nstack_model = StackingClassifier(estimators=base_learners, final_estimator=final_estimator)\nstack_scores = cross_validate(stack_model, data, labels, scoring='accuracy', cv=cv, return_train_score=True)\nprint('%i fold Stacking Accuracy train score: %.3f (%.3f)' % (5, np.mean(stack_scores['train_score']), np.std(stack_scores['train_score'])))\nprint('%i fold Stacking Accuracy test score: %.3f (%.3f)' % (5, np.mean(stack_scores['test_score']), np.std(stack_scores['test_score'])))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:58:52.142278Z","iopub.execute_input":"2022-04-29T11:58:52.142640Z","iopub.status.idle":"2022-04-29T11:58:52.505520Z","shell.execute_reply.started":"2022-04-29T11:58:52.142606Z","shell.execute_reply":"2022-04-29T11:58:52.504572Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"5 fold Stacking Accuracy train score: 1.000 (0.000)\n5 fold Stacking Accuracy test score: 0.769 (0.032)\nCPU times: user 354 ms, sys: 2.63 ms, total: 356 ms\nWall time: 354 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nrf_model = RandomForestClassifier(n_estimators=num_estimator)\nrf_scores = cross_validate(rf_model, data, labels, scoring='accuracy', cv=cv, return_train_score=True)\nprint('%i fold RandomForest Accuracy train score: %.3f (%.3f)' % (5, np.mean(rf_scores['train_score']), np.std(rf_scores['train_score'])))\nprint('%i fold RandomForest Accuracy test score: %.3f (%.3f)' % (5, np.mean(rf_scores['test_score']), np.std(rf_scores['test_score'])))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:58:54.366716Z","iopub.execute_input":"2022-04-29T11:58:54.367021Z","iopub.status.idle":"2022-04-29T11:58:54.443996Z","shell.execute_reply.started":"2022-04-29T11:58:54.366988Z","shell.execute_reply":"2022-04-29T11:58:54.443092Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"5 fold RandomForest Accuracy train score: 0.975 (0.010)\n5 fold RandomForest Accuracy test score: 0.812 (0.031)\nCPU times: user 69.3 ms, sys: 2.88 ms, total: 72.1 ms\nWall time: 71.5 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nab_model = AdaBoostClassifier(n_estimators=num_estimator)\nab_scores = cross_validate(ab_model, data, labels, scoring='accuracy', cv=cv, return_train_score=True)\nprint('%i fold AdaBoost Accuracy train score: %.3f (%.3f)' % (5, np.mean(ab_scores['train_score']), np.std(ab_scores['train_score'])))\nprint('%i fold AdaBoost Accuracy test score: %.3f (%.3f)' % (5, np.mean(ab_scores['test_score']), np.std(ab_scores['test_score'])))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T11:58:56.647104Z","iopub.execute_input":"2022-04-29T11:58:56.647600Z","iopub.status.idle":"2022-04-29T11:58:56.718665Z","shell.execute_reply.started":"2022-04-29T11:58:56.647565Z","shell.execute_reply":"2022-04-29T11:58:56.717600Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"5 fold AdaBoost Accuracy train score: 0.845 (0.008)\n5 fold AdaBoost Accuracy test score: 0.841 (0.049)\nCPU times: user 64.5 ms, sys: 0 ns, total: 64.5 ms\nWall time: 64.8 ms\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* Mean of accuracy is the best for AdaBoost with 5 estimator regarding the test accuracy, standard deviation for RF but there the mean is lower\n* For memory: AdaBoost using less memory, than the rest\n* For speed: RandomForest and Stacking can be parallelized, but AdaBoost was faster for me\n* For performance: AdaBoost (with 50 estimator for AB and RF, RF was better)","metadata":{}}]}